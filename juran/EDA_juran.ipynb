{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb02cf9e-4e6b-4e73-8359-d8ef3e2aa1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90a082fb-ff73-41a9-b277-f8cc2062171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycaret in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (8.26.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (8.1.5)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (4.66.5)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.5.3)\n",
      "Requirement already satisfied: jinja2>=3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (3.1.4)\n",
      "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.11.4)\n",
      "Requirement already satisfied: joblib<1.4,>=1.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>1.4.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.4.2)\n",
      "Requirement already satisfied: pyod>=1.1.3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (2.0.2)\n",
      "Requirement already satisfied: imbalanced-learn>=0.12.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.12.3)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (2.6.3)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (4.5.0)\n",
      "Requirement already satisfied: numba>=0.55.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.60.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.9.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (6.0.0)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (2.1.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (8.5.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (5.10.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (3.0.0)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (2.1.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (3.5.0)\n",
      "Requirement already satisfied: matplotlib<3.8.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (3.7.5)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.3.7)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.5)\n",
      "Requirement already satisfied: plotly>=5.14.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (5.24.1)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.2.1)\n",
      "Requirement already satisfied: schemdraw==0.15 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.15)\n",
      "Requirement already satisfied: plotly-resampler>=0.8.3.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.10.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.14.3)\n",
      "Requirement already satisfied: sktime==0.26.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (0.26.0)\n",
      "Requirement already satisfied: tbats>=1.1.3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (1.1.3)\n",
      "Requirement already satisfied: pmdarima>=2.0.4 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pycaret) (2.0.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from sktime==0.26.0->pycaret) (24.1)\n",
      "Requirement already satisfied: scikit-base<0.8.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from category-encoders>=2.4.0->pycaret) (0.5.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn>=0.12.0->pycaret) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=4.12.0->pycaret) (3.20.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=5.5.0->pycaret) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret) (3.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib<3.8.0->pycaret) (2.9.0.post0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from nbformat>=4.2.0->pycaret) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas<2.2.0->pycaret) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from plotly>=5.14.0->pycaret) (9.0.0)\n",
      "Requirement already satisfied: dash>=2.9.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (2.18.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.7)\n",
      "Requirement already satisfied: tsdownsample>=0.1.3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.3)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pmdarima>=2.0.4->pycaret) (3.0.11)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pmdarima>=2.0.4->pycaret) (2.2.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from pmdarima>=2.0.4->pycaret) (72.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.27.1->pycaret) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.27.1->pycaret) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.27.1->pycaret) (2024.7.4)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.4)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (5.0.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (306)\n",
      "Requirement already satisfied: six in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from patsy>=0.5.1->category-encoders>=2.4.0->pycaret) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\juran\\anaconda3\\envs\\myenv\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a94f4e97-7aa8-43fc-8514-3366662733e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fab197b0-0014-4b07-9c0c-07ceab853e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycaret\n",
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76b6c964-90fa-4e78-8de3-557be2991660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b8769b05-dfcd-44c1-a0a3-928d3798de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = pd.read_csv('../bank.csv')\n",
    "df_bank.drop(columns = ['duration'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "25aa2276-05e9-4fa5-83f0-b9fb725af41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11162 entries, 0 to 11161\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        11162 non-null  int64 \n",
      " 1   job        11162 non-null  object\n",
      " 2   marital    11162 non-null  object\n",
      " 3   education  11162 non-null  object\n",
      " 4   default    11162 non-null  object\n",
      " 5   balance    11162 non-null  int64 \n",
      " 6   housing    11162 non-null  object\n",
      " 7   loan       11162 non-null  object\n",
      " 8   contact    11162 non-null  object\n",
      " 9   day        11162 non-null  int64 \n",
      " 10  month      11162 non-null  object\n",
      " 11  campaign   11162 non-null  int64 \n",
      " 12  pdays      11162 non-null  int64 \n",
      " 13  previous   11162 non-null  int64 \n",
      " 14  poutcome   11162 non-null  object\n",
      " 15  deposit    11162 non-null  object\n",
      "dtypes: int64(6), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "68a91328-5afa-4ee7-bb42-382ed045652b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     5873\n",
       "yes    5289\n",
       "Name: deposit, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2aef7f67-1468-4838-9693-fadf3922a655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "deposit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "82b75edd-0d71-47b9-908f-4f9d04a53410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank['pdays'] = np.where(df_bank['pdays'] == -1, 'no', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "563f8291-abae-4d97-951c-99eb9c4708b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     8324\n",
       "yes    2838\n",
       "Name: pdays, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['pdays'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9394d200-d1ae-4680-a840-c0d60ffb7140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'balance', 'day', 'campaign', 'previous']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수치형 컬럼 추출하는 방법\n",
    "num_cols = list(df_bank.describe().columns)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ab8aad6b-04b7-498d-8f90-68db31ded4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contact',\n",
       " 'poutcome',\n",
       " 'deposit',\n",
       " 'marital',\n",
       " 'month',\n",
       " 'housing',\n",
       " 'education',\n",
       " 'default',\n",
       " 'job',\n",
       " 'loan',\n",
       " 'pdays']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#범주형 컬럼 추출하는 방법\n",
    "cat_cols = list(set(df_bank.columns) - set(df_bank.describe().columns))\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a85de19d-e1f1-4402-a9a9-493e7af05313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1049_row10_col1, #T_b1049_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1049\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1049_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_b1049_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b1049_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_b1049_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b1049_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_b1049_row1_col1\" class=\"data row1 col1\" >deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b1049_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_b1049_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b1049_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_b1049_row3_col1\" class=\"data row3 col1\" >no: 0, yes: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b1049_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_b1049_row4_col1\" class=\"data row4 col1\" >(11162, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b1049_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_b1049_row5_col1\" class=\"data row5 col1\" >(11162, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b1049_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_b1049_row6_col1\" class=\"data row6 col1\" >(8929, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b1049_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_b1049_row7_col1\" class=\"data row7 col1\" >(2233, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b1049_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_b1049_row8_col1\" class=\"data row8 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b1049_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_b1049_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b1049_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_b1049_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b1049_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_b1049_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b1049_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_b1049_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b1049_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_b1049_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b1049_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_b1049_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b1049_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_b1049_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b1049_row16_col0\" class=\"data row16 col0\" >Normalize</td>\n",
       "      <td id=\"T_b1049_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b1049_row17_col0\" class=\"data row17 col0\" >Normalize method</td>\n",
       "      <td id=\"T_b1049_row17_col1\" class=\"data row17 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b1049_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_b1049_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b1049_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_b1049_row19_col1\" class=\"data row19 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_b1049_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_b1049_row20_col1\" class=\"data row20 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_b1049_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_b1049_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_b1049_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_b1049_row22_col1\" class=\"data row22 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_b1049_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_b1049_row23_col1\" class=\"data row23 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1049_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_b1049_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_b1049_row24_col1\" class=\"data row24 col1\" >0ae9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x253e10779d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = setup(df_bank, target = 'deposit', train_size = 0.8, normalize = True, normalize_method='zscore', session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "65508475-5391-48fa-ac0e-48881a9de5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juran\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.\n",
      "  warnings.warn(msg)  # print on screen\n",
      "C:\\Users\\juran\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.\n",
      "  warnings.warn(msg)  # print on screen\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = get_config('X_train_transformed')\n",
    "y_train = get_config('y_train')\n",
    "X_test_transformed = get_config('X_test_transformed')\n",
    "y_test = get_config('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "814ca404-887d-4fae-ae57-4b13b7ef5224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>day</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>0.060709</td>\n",
       "      <td>1.840575</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>1.468727</td>\n",
       "      <td>2.512540</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10963</th>\n",
       "      <td>-0.191067</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>6.277158</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>2.540326</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.446629</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>1.937007</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.140605</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>0.144635</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>5.137078</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.189600</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>1.937007</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.140605</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.559698</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>-1.366022</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>5.527317</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.384675</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>1.231515</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>2.662397</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>3.632568</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.338924</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>0.994303</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>6.321291</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.559698</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>1.403516</td>\n",
       "      <td>1.840575</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.399925</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-0.666181</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>10.023268</td>\n",
       "      <td>-0.559698</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>0.964632</td>\n",
       "      <td>-1.721894</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>3.105226</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10609</th>\n",
       "      <td>-1.282097</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>5.527317</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>3.682987</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>1.350121</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>-0.694619</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>2.707266</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.139084</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>0.282667</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>0.964632</td>\n",
       "      <td>-1.721894</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>4.540909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>0.648187</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>2.238927</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.526374</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>2.565111</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>0.875697</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>2.508971</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>0.562504</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>0.480336</td>\n",
       "      <td>1.840575</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.145438</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.377817</td>\n",
       "      <td>2.512540</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.27055</td>\n",
       "      <td>-0.398570</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8929 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  job_management  job_housemaid  job_self-employed  job_student  ...  previous  poutcome_unknown  poutcome_failure  poutcome_success  poutcome_other\n",
       "6270   0.060709        1.840575      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "10963 -0.191067       -0.543309       6.277158          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "9909   0.144635       -0.543309      -0.159308           5.137078    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "2143  -1.366022       -0.543309      -0.159308          -0.194663     5.527317  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "4869   2.662397       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "...         ...             ...            ...                ...          ...  ...       ...               ...               ...               ...             ...\n",
       "3011   1.403516        1.840575      -0.159308          -0.194663    -0.180920  ...  0.964632         -1.721894         -0.355133          3.105226       -0.220220\n",
       "10609 -1.282097       -0.543309      -0.159308          -0.194663     5.527317  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "7504  -0.694619       -0.543309      -0.159308          -0.194663    -0.180920  ...  0.964632         -1.721894         -0.355133         -0.322038        4.540909\n",
       "8795   0.648187       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "9250   0.480336        1.840575      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "\n",
       "[8929 rows x 47 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0fd05779-0cc6-43c2-9854-08734f8a4bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juran\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.\n",
      "  warnings.warn(msg)  # print on screen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8368     no\n",
       "9300     no\n",
       "5254    yes\n",
       "1581    yes\n",
       "9123     no\n",
       "       ... \n",
       "6546     no\n",
       "242     yes\n",
       "6928     no\n",
       "142     yes\n",
       "4632    yes\n",
       "Name: deposit, Length: 2233, dtype: category\n",
       "Categories (2, object): ['no', 'yes']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_config('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f385b620-d390-4fbf-96fa-99d964310865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>day</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>0.060709</td>\n",
       "      <td>1.840575</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>1.468727</td>\n",
       "      <td>2.512540</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10963</th>\n",
       "      <td>-0.191067</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>6.277158</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>2.540326</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.446629</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>1.937007</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.140605</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>0.144635</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>5.137078</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.189600</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>1.937007</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.140605</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.559698</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>-1.366022</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>5.527317</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.384675</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>1.231515</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>2.662397</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>3.632568</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.338924</td>\n",
       "      <td>-0.946017</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>0.994303</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>6.321291</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.559698</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>-0.107141</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>3.341384</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.481259</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>2.565111</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.615029</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>3.696179</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.396411</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>2.707266</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.211522</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>1.937007</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.259211</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>2.839890</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>-0.274992</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>2.188728</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>1.475280</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>2.540326</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.481259</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-1.021999</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-0.274992</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>2.707266</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>-0.446642</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-1.153306</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>2.783046</td>\n",
       "      <td>-0.697447</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>1.013644</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>-0.418352</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>1.937007</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>1.231515</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>-0.352126</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.185630</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.360408</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>-0.220220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>-0.610694</td>\n",
       "      <td>-0.543309</td>\n",
       "      <td>-0.159308</td>\n",
       "      <td>-0.194663</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>-0.275287</td>\n",
       "      <td>-0.369376</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>-0.299277</td>\n",
       "      <td>2.238927</td>\n",
       "      <td>-0.182564</td>\n",
       "      <td>-0.173182</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.677838</td>\n",
       "      <td>-0.359318</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>-0.393650</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-0.217975</td>\n",
       "      <td>-0.122495</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>1.057063</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>-0.516260</td>\n",
       "      <td>-0.272926</td>\n",
       "      <td>-0.073151</td>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-0.581101</td>\n",
       "      <td>-0.158196</td>\n",
       "      <td>-0.296604</td>\n",
       "      <td>-0.270550</td>\n",
       "      <td>-0.39857</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>2.839890</td>\n",
       "      <td>-0.303258</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-0.172838</td>\n",
       "      <td>-0.099768</td>\n",
       "      <td>-0.559698</td>\n",
       "      <td>1.720872</td>\n",
       "      <td>0.081272</td>\n",
       "      <td>-1.721894</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>4.540909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11162 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  job_management  job_housemaid  job_self-employed  job_student  ...  previous  poutcome_unknown  poutcome_failure  poutcome_success  poutcome_other\n",
       "6270   0.060709        1.840575      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "10963 -0.191067       -0.543309       6.277158          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "9909   0.144635       -0.543309      -0.159308           5.137078    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "2143  -1.366022       -0.543309      -0.159308          -0.194663     5.527317  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "4869   2.662397       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "...         ...             ...            ...                ...          ...  ...       ...               ...               ...               ...             ...\n",
       "6546  -0.107141       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "242    0.396411       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "6928  -0.274992       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "142   -0.274992       -0.543309      -0.159308          -0.194663    -0.180920  ... -0.360408          0.580756         -0.355133         -0.322038       -0.220220\n",
       "4632  -0.610694       -0.543309      -0.159308          -0.194663    -0.180920  ...  0.081272         -1.721894         -0.355133         -0.322038        4.540909\n",
       "\n",
       "[11162 rows x 47 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import setup, get_config\n",
    "\n",
    "# Transformed data 확인\n",
    "transformed_data = get_config('X_transformed')\n",
    "\n",
    "# 변환된 데이터 출력\n",
    "pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e6a8403b-014d-447c-9226-388a91396d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_745bf th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_745bf_row0_col0, #T_745bf_row0_col5, #T_745bf_row1_col0, #T_745bf_row1_col1, #T_745bf_row1_col2, #T_745bf_row1_col3, #T_745bf_row1_col4, #T_745bf_row1_col6, #T_745bf_row1_col7, #T_745bf_row2_col0, #T_745bf_row2_col1, #T_745bf_row2_col2, #T_745bf_row2_col3, #T_745bf_row2_col4, #T_745bf_row2_col5, #T_745bf_row2_col6, #T_745bf_row2_col7, #T_745bf_row3_col0, #T_745bf_row3_col1, #T_745bf_row3_col2, #T_745bf_row3_col3, #T_745bf_row3_col4, #T_745bf_row3_col5, #T_745bf_row3_col6, #T_745bf_row3_col7, #T_745bf_row4_col0, #T_745bf_row4_col1, #T_745bf_row4_col2, #T_745bf_row4_col3, #T_745bf_row4_col4, #T_745bf_row4_col5, #T_745bf_row4_col6, #T_745bf_row4_col7, #T_745bf_row5_col0, #T_745bf_row5_col1, #T_745bf_row5_col2, #T_745bf_row5_col3, #T_745bf_row5_col4, #T_745bf_row5_col5, #T_745bf_row5_col6, #T_745bf_row5_col7, #T_745bf_row6_col0, #T_745bf_row6_col1, #T_745bf_row6_col2, #T_745bf_row6_col3, #T_745bf_row6_col4, #T_745bf_row6_col5, #T_745bf_row6_col6, #T_745bf_row6_col7, #T_745bf_row7_col0, #T_745bf_row7_col1, #T_745bf_row7_col2, #T_745bf_row7_col3, #T_745bf_row7_col4, #T_745bf_row7_col5, #T_745bf_row7_col6, #T_745bf_row7_col7, #T_745bf_row8_col0, #T_745bf_row8_col1, #T_745bf_row8_col2, #T_745bf_row8_col3, #T_745bf_row8_col4, #T_745bf_row8_col5, #T_745bf_row8_col6, #T_745bf_row8_col7, #T_745bf_row9_col0, #T_745bf_row9_col1, #T_745bf_row9_col2, #T_745bf_row9_col3, #T_745bf_row9_col4, #T_745bf_row9_col5, #T_745bf_row9_col6, #T_745bf_row9_col7, #T_745bf_row10_col0, #T_745bf_row10_col1, #T_745bf_row10_col2, #T_745bf_row10_col3, #T_745bf_row10_col4, #T_745bf_row10_col5, #T_745bf_row10_col6, #T_745bf_row10_col7, #T_745bf_row11_col0, #T_745bf_row11_col1, #T_745bf_row11_col2, #T_745bf_row11_col3, #T_745bf_row11_col4, #T_745bf_row11_col5, #T_745bf_row11_col6, #T_745bf_row11_col7, #T_745bf_row12_col0, #T_745bf_row12_col1, #T_745bf_row12_col2, #T_745bf_row12_col3, #T_745bf_row12_col4, #T_745bf_row12_col5, #T_745bf_row12_col6, #T_745bf_row12_col7, #T_745bf_row13_col0, #T_745bf_row13_col1, #T_745bf_row13_col2, #T_745bf_row13_col3, #T_745bf_row13_col4, #T_745bf_row13_col5, #T_745bf_row13_col6, #T_745bf_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_745bf_row0_col1, #T_745bf_row0_col2, #T_745bf_row0_col3, #T_745bf_row0_col4, #T_745bf_row0_col6, #T_745bf_row0_col7, #T_745bf_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_745bf_row0_col8, #T_745bf_row1_col8, #T_745bf_row2_col8, #T_745bf_row3_col8, #T_745bf_row4_col8, #T_745bf_row5_col8, #T_745bf_row6_col8, #T_745bf_row7_col8, #T_745bf_row8_col8, #T_745bf_row9_col8, #T_745bf_row10_col8, #T_745bf_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_745bf_row12_col8, #T_745bf_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_745bf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_745bf_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_745bf_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_745bf_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_745bf_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_745bf_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_745bf_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_745bf_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_745bf_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_745bf_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row0\" class=\"row_heading level0 row0\" >gbc</th>\n",
       "      <td id=\"T_745bf_row0_col0\" class=\"data row0 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_745bf_row0_col1\" class=\"data row0 col1\" >0.7319</td>\n",
       "      <td id=\"T_745bf_row0_col2\" class=\"data row0 col2\" >0.7894</td>\n",
       "      <td id=\"T_745bf_row0_col3\" class=\"data row0 col3\" >0.7319</td>\n",
       "      <td id=\"T_745bf_row0_col4\" class=\"data row0 col4\" >0.7386</td>\n",
       "      <td id=\"T_745bf_row0_col5\" class=\"data row0 col5\" >0.7277</td>\n",
       "      <td id=\"T_745bf_row0_col6\" class=\"data row0 col6\" >0.4566</td>\n",
       "      <td id=\"T_745bf_row0_col7\" class=\"data row0 col7\" >0.4661</td>\n",
       "      <td id=\"T_745bf_row0_col8\" class=\"data row0 col8\" >0.3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_745bf_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_745bf_row1_col1\" class=\"data row1 col1\" >0.7314</td>\n",
       "      <td id=\"T_745bf_row1_col2\" class=\"data row1 col2\" >0.7872</td>\n",
       "      <td id=\"T_745bf_row1_col3\" class=\"data row1 col3\" >0.7314</td>\n",
       "      <td id=\"T_745bf_row1_col4\" class=\"data row1 col4\" >0.7367</td>\n",
       "      <td id=\"T_745bf_row1_col5\" class=\"data row1 col5\" >0.7279</td>\n",
       "      <td id=\"T_745bf_row1_col6\" class=\"data row1 col6\" >0.4563</td>\n",
       "      <td id=\"T_745bf_row1_col7\" class=\"data row1 col7\" >0.4641</td>\n",
       "      <td id=\"T_745bf_row1_col8\" class=\"data row1 col8\" >0.1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_745bf_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_745bf_row2_col1\" class=\"data row2 col1\" >0.7171</td>\n",
       "      <td id=\"T_745bf_row2_col2\" class=\"data row2 col2\" >0.7784</td>\n",
       "      <td id=\"T_745bf_row2_col3\" class=\"data row2 col3\" >0.7171</td>\n",
       "      <td id=\"T_745bf_row2_col4\" class=\"data row2 col4\" >0.7184</td>\n",
       "      <td id=\"T_745bf_row2_col5\" class=\"data row2 col5\" >0.7153</td>\n",
       "      <td id=\"T_745bf_row2_col6\" class=\"data row2 col6\" >0.4293</td>\n",
       "      <td id=\"T_745bf_row2_col7\" class=\"data row2 col7\" >0.4322</td>\n",
       "      <td id=\"T_745bf_row2_col8\" class=\"data row2 col8\" >0.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row3\" class=\"row_heading level0 row3\" >ada</th>\n",
       "      <td id=\"T_745bf_row3_col0\" class=\"data row3 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_745bf_row3_col1\" class=\"data row3 col1\" >0.7151</td>\n",
       "      <td id=\"T_745bf_row3_col2\" class=\"data row3 col2\" >0.7703</td>\n",
       "      <td id=\"T_745bf_row3_col3\" class=\"data row3 col3\" >0.7151</td>\n",
       "      <td id=\"T_745bf_row3_col4\" class=\"data row3 col4\" >0.7200</td>\n",
       "      <td id=\"T_745bf_row3_col5\" class=\"data row3 col5\" >0.7111</td>\n",
       "      <td id=\"T_745bf_row3_col6\" class=\"data row3 col6\" >0.4230</td>\n",
       "      <td id=\"T_745bf_row3_col7\" class=\"data row3 col7\" >0.4307</td>\n",
       "      <td id=\"T_745bf_row3_col8\" class=\"data row3 col8\" >0.1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row4\" class=\"row_heading level0 row4\" >ridge</th>\n",
       "      <td id=\"T_745bf_row4_col0\" class=\"data row4 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_745bf_row4_col1\" class=\"data row4 col1\" >0.7028</td>\n",
       "      <td id=\"T_745bf_row4_col2\" class=\"data row4 col2\" >0.7623</td>\n",
       "      <td id=\"T_745bf_row4_col3\" class=\"data row4 col3\" >0.7028</td>\n",
       "      <td id=\"T_745bf_row4_col4\" class=\"data row4 col4\" >0.7094</td>\n",
       "      <td id=\"T_745bf_row4_col5\" class=\"data row4 col5\" >0.6975</td>\n",
       "      <td id=\"T_745bf_row4_col6\" class=\"data row4 col6\" >0.3971</td>\n",
       "      <td id=\"T_745bf_row4_col7\" class=\"data row4 col7\" >0.4070</td>\n",
       "      <td id=\"T_745bf_row4_col8\" class=\"data row4 col8\" >0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_745bf_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_745bf_row5_col1\" class=\"data row5 col1\" >0.7028</td>\n",
       "      <td id=\"T_745bf_row5_col2\" class=\"data row5 col2\" >0.7623</td>\n",
       "      <td id=\"T_745bf_row5_col3\" class=\"data row5 col3\" >0.7028</td>\n",
       "      <td id=\"T_745bf_row5_col4\" class=\"data row5 col4\" >0.7094</td>\n",
       "      <td id=\"T_745bf_row5_col5\" class=\"data row5 col5\" >0.6975</td>\n",
       "      <td id=\"T_745bf_row5_col6\" class=\"data row5 col6\" >0.3971</td>\n",
       "      <td id=\"T_745bf_row5_col7\" class=\"data row5 col7\" >0.4070</td>\n",
       "      <td id=\"T_745bf_row5_col8\" class=\"data row5 col8\" >0.0780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "      <td id=\"T_745bf_row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_745bf_row6_col1\" class=\"data row6 col1\" >0.7022</td>\n",
       "      <td id=\"T_745bf_row6_col2\" class=\"data row6 col2\" >0.7630</td>\n",
       "      <td id=\"T_745bf_row6_col3\" class=\"data row6 col3\" >0.7022</td>\n",
       "      <td id=\"T_745bf_row6_col4\" class=\"data row6 col4\" >0.7084</td>\n",
       "      <td id=\"T_745bf_row6_col5\" class=\"data row6 col5\" >0.6971</td>\n",
       "      <td id=\"T_745bf_row6_col6\" class=\"data row6 col6\" >0.3962</td>\n",
       "      <td id=\"T_745bf_row6_col7\" class=\"data row6 col7\" >0.4056</td>\n",
       "      <td id=\"T_745bf_row6_col8\" class=\"data row6 col8\" >0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row7\" class=\"row_heading level0 row7\" >et</th>\n",
       "      <td id=\"T_745bf_row7_col0\" class=\"data row7 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_745bf_row7_col1\" class=\"data row7 col1\" >0.6958</td>\n",
       "      <td id=\"T_745bf_row7_col2\" class=\"data row7 col2\" >0.7517</td>\n",
       "      <td id=\"T_745bf_row7_col3\" class=\"data row7 col3\" >0.6958</td>\n",
       "      <td id=\"T_745bf_row7_col4\" class=\"data row7 col4\" >0.6959</td>\n",
       "      <td id=\"T_745bf_row7_col5\" class=\"data row7 col5\" >0.6946</td>\n",
       "      <td id=\"T_745bf_row7_col6\" class=\"data row7 col6\" >0.3873</td>\n",
       "      <td id=\"T_745bf_row7_col7\" class=\"data row7 col7\" >0.3887</td>\n",
       "      <td id=\"T_745bf_row7_col8\" class=\"data row7 col8\" >0.2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "      <td id=\"T_745bf_row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_745bf_row8_col1\" class=\"data row8 col1\" >0.6781</td>\n",
       "      <td id=\"T_745bf_row8_col2\" class=\"data row8 col2\" >0.7209</td>\n",
       "      <td id=\"T_745bf_row8_col3\" class=\"data row8 col3\" >0.6781</td>\n",
       "      <td id=\"T_745bf_row8_col4\" class=\"data row8 col4\" >0.6784</td>\n",
       "      <td id=\"T_745bf_row8_col5\" class=\"data row8 col5\" >0.6763</td>\n",
       "      <td id=\"T_745bf_row8_col6\" class=\"data row8 col6\" >0.3509</td>\n",
       "      <td id=\"T_745bf_row8_col7\" class=\"data row8 col7\" >0.3530</td>\n",
       "      <td id=\"T_745bf_row8_col8\" class=\"data row8 col8\" >0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_745bf_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_745bf_row9_col1\" class=\"data row9 col1\" >0.6776</td>\n",
       "      <td id=\"T_745bf_row9_col2\" class=\"data row9 col2\" >0.7376</td>\n",
       "      <td id=\"T_745bf_row9_col3\" class=\"data row9 col3\" >0.6776</td>\n",
       "      <td id=\"T_745bf_row9_col4\" class=\"data row9 col4\" >0.6952</td>\n",
       "      <td id=\"T_745bf_row9_col5\" class=\"data row9 col5\" >0.6646</td>\n",
       "      <td id=\"T_745bf_row9_col6\" class=\"data row9 col6\" >0.3416</td>\n",
       "      <td id=\"T_745bf_row9_col7\" class=\"data row9 col7\" >0.3644</td>\n",
       "      <td id=\"T_745bf_row9_col8\" class=\"data row9 col8\" >0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_745bf_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_745bf_row10_col1\" class=\"data row10 col1\" >0.6609</td>\n",
       "      <td id=\"T_745bf_row10_col2\" class=\"data row10 col2\" >0.7096</td>\n",
       "      <td id=\"T_745bf_row10_col3\" class=\"data row10 col3\" >0.6609</td>\n",
       "      <td id=\"T_745bf_row10_col4\" class=\"data row10 col4\" >0.6653</td>\n",
       "      <td id=\"T_745bf_row10_col5\" class=\"data row10 col5\" >0.6549</td>\n",
       "      <td id=\"T_745bf_row10_col6\" class=\"data row10 col6\" >0.3124</td>\n",
       "      <td id=\"T_745bf_row10_col7\" class=\"data row10 col7\" >0.3204</td>\n",
       "      <td id=\"T_745bf_row10_col8\" class=\"data row10 col8\" >0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_745bf_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_745bf_row11_col1\" class=\"data row11 col1\" >0.6350</td>\n",
       "      <td id=\"T_745bf_row11_col2\" class=\"data row11 col2\" >0.6342</td>\n",
       "      <td id=\"T_745bf_row11_col3\" class=\"data row11 col3\" >0.6350</td>\n",
       "      <td id=\"T_745bf_row11_col4\" class=\"data row11 col4\" >0.6353</td>\n",
       "      <td id=\"T_745bf_row11_col5\" class=\"data row11 col5\" >0.6350</td>\n",
       "      <td id=\"T_745bf_row11_col6\" class=\"data row11 col6\" >0.2683</td>\n",
       "      <td id=\"T_745bf_row11_col7\" class=\"data row11 col7\" >0.2684</td>\n",
       "      <td id=\"T_745bf_row11_col8\" class=\"data row11 col8\" >0.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_745bf_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_745bf_row12_col1\" class=\"data row12 col1\" >0.6259</td>\n",
       "      <td id=\"T_745bf_row12_col2\" class=\"data row12 col2\" >0.7187</td>\n",
       "      <td id=\"T_745bf_row12_col3\" class=\"data row12 col3\" >0.6259</td>\n",
       "      <td id=\"T_745bf_row12_col4\" class=\"data row12 col4\" >0.7131</td>\n",
       "      <td id=\"T_745bf_row12_col5\" class=\"data row12 col5\" >0.5697</td>\n",
       "      <td id=\"T_745bf_row12_col6\" class=\"data row12 col6\" >0.2227</td>\n",
       "      <td id=\"T_745bf_row12_col7\" class=\"data row12 col7\" >0.3072</td>\n",
       "      <td id=\"T_745bf_row12_col8\" class=\"data row12 col8\" >0.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_745bf_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_745bf_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_745bf_row13_col1\" class=\"data row13 col1\" >0.5262</td>\n",
       "      <td id=\"T_745bf_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_745bf_row13_col3\" class=\"data row13 col3\" >0.5262</td>\n",
       "      <td id=\"T_745bf_row13_col4\" class=\"data row13 col4\" >0.2768</td>\n",
       "      <td id=\"T_745bf_row13_col5\" class=\"data row13 col5\" >0.3628</td>\n",
       "      <td id=\"T_745bf_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_745bf_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_745bf_row13_col8\" class=\"data row13 col8\" >0.0720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x253e339fb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare baseline models\n",
    "top3_models = compare_models(sort = 'Recall', n_select = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "82dc5bfb-4d2e-4f3a-93ad-9ddfa4123af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='log_loss', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                            n_estimators=100, n_iter_no_change=None,\n",
       "                            random_state=123, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0),\n",
       " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        monotonic_cst=None, n_estimators=100, n_jobs=-1,\n",
       "                        oob_score=False, random_state=123, verbose=0,\n",
       "                        warm_start=False)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bebe676b-9473-4b6b-9355-40153421bbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;, init=None,\n",
       "                           learning_rate=0.1, loss=&#x27;log_loss&#x27;, max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=100, n_iter_no_change=None,\n",
       "                           random_state=123, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;, init=None,\n",
       "                           learning_rate=0.1, loss=&#x27;log_loss&#x27;, max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=100, n_iter_no_change=None,\n",
       "                           random_state=123, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=100, n_iter_no_change=None,\n",
       "                           random_state=123, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ec949883-879b-4199-8196-c312b54afa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [top3_models[0], top3_models[1], top3_models[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "571ec386-1ebe-4761-858e-07f142c377d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4231, number of negative: 4698\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 538\n",
      "[LightGBM] [Info] Number of data points in the train set: 8929, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.473849 -> initscore=-0.104699\n",
      "[LightGBM] [Info] Start training from score -0.104699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.72      0.83      0.77      1175\n",
      "         yes       0.77      0.64      0.70      1058\n",
      "\n",
      "    accuracy                           0.74      2233\n",
      "   macro avg       0.74      0.73      0.73      2233\n",
      "weighted avg       0.74      0.74      0.73      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 상위 3개 모델로 Voting Classifier 생성\n",
    "models = [top3_models[0], top3_models[1], top3_models[2]]\n",
    "voting_clf = VotingClassifier(estimators=[('GBC', models[0]), ('LGBMC', models[1]), ('RFC', models[2])], voting='soft')\n",
    "\n",
    "# 모델 훈련\n",
    "voting_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "predictions = voting_clf.predict(X_test_transformed)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a746e-3cb8-492e-a37f-0c16ca7a6632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "02ee9e7a-9e98-4593-8621-d437cdbc873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=[0 1] and y_pred=['no' 'yes']. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m \u001b[43m_union1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:118\u001b[0m, in \u001b[0;36m_union1d\u001b[1;34m(a, b, xp)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m b\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:932\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03mFind the union of two arrays.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoting_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\classification\\functional.py:1725\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, verbose, display_format)\u001b[0m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1613\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;124;03m    This function analyzes the performance of a trained model on holdout set.\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03m    It may require re-training the model in certain cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \n\u001b[0;32m   1723\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CURRENT_EXPERIMENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\classification\\oop.py:2071\u001b[0m, in \u001b[0;36mClassificationExperiment.plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, verbose, display_format)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1959\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1969\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1970\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;124;03m    This function analyzes the performance of a trained model on holdout set.\u001b[39;00m\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;124;03m    It may require re-training the model in certain cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \n\u001b[0;32m   2069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2075\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2077\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2082\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2045\u001b[0m, in \u001b[0;36m_TabularExperiment.plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, verbose, display_format)\u001b[0m\n\u001b[0;32m   1933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1935\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1946\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1947\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;124;03m    This function takes a trained model object and returns a plot based on the\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;124;03m    test / hold-out set. The process may require the model to be re-trained in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \n\u001b[0;32m   2044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:1913\u001b[0m, in \u001b[0;36m_TabularExperiment._plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, verbose, system, display, display_format)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;66;03m# execute the plot method\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[1;32m-> 1913\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m   1915\u001b[0m     plot_filename \u001b[38;5;241m=\u001b[39m ret\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:1139\u001b[0m, in \u001b[0;36m_TabularExperiment._plot_model.<locals>.auc\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myellowbrick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROCAUC\n\u001b[0;32m   1138\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m ROCAUC(estimator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplot_kwargs)\n\u001b[1;32m-> 1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshow_yellowbrick_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\plots\\yellowbrick.py:103\u001b[0m, in \u001b[0;36mshow_yellowbrick_plot\u001b[1;34m(visualizer, X_train, y_train, X_test, y_test, name, handle_train, handle_test, scale, save, fit_kwargs, display_format, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m handle_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    102\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScoring test/hold-out set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m     \u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m plot_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\yellowbrick\\classifier\\rocauc.py:264\u001b[0m, in \u001b[0;36mROCAUC.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mGenerates the predicted target values using the Scikit-Learn\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mestimator.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Global accuracy unless micro or macro scores are requested.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Call super to check if fitted and to compute self.score_\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# NOTE: this sets score to the base score if neither macro nor micro\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mROCAUC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# Compute the predictions for the test data\u001b[39;00m\n\u001b[0;32m    267\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_y_scores(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\yellowbrick\\classifier\\base.py:238\u001b[0m, in \u001b[0;36mClassificationScoreVisualizer.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not determine class_counts_ from previously fitted classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m         YellowbrickWarning,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# This method implements ScoreVisualizer (do not call super).\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:119\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m _union1d(y_true, y_pred, xp)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxp\u001b[38;5;241m.\u001b[39munique(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions provided by the classifier coincides with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    127\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=[0 1] and y_pred=['no' 'yes']. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x550 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(voting_clf, plot='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "63615dba-ff58-4fbd-9394-34ef0aac2822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juran\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.\n",
      "  warnings.warn(msg)  # print on screen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8368     no\n",
       "9300     no\n",
       "5254    yes\n",
       "1581    yes\n",
       "9123     no\n",
       "       ... \n",
       "6546     no\n",
       "242     yes\n",
       "6928     no\n",
       "142     yes\n",
       "4632    yes\n",
       "Name: deposit, Length: 2233, dtype: category\n",
       "Categories (2, object): ['no', 'yes']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_config('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "33e0d67a-1c8d-4d4a-9194-5d1c3b492513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juran\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.\n",
      "  warnings.warn(msg)  # print on screen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['no', 'yes'], ordered=False)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_config('y_test').dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ba1a54bd-1335-4b9a-83a6-abd057f17ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        yes\n",
       "1        yes\n",
       "2        yes\n",
       "3        yes\n",
       "4        yes\n",
       "        ... \n",
       "11157     no\n",
       "11158     no\n",
       "11159     no\n",
       "11160     no\n",
       "11161     no\n",
       "Name: deposit, Length: 11162, dtype: object"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "25576816-c526-412c-93b4-5a0aa1edead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank['deposit'] = df_bank['deposit'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2dd9bac5-3098-4168-b42a-4fbaaa744f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=[0 1] and y_pred=['no' 'yes']. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m \u001b[43m_union1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:118\u001b[0m, in \u001b[0;36m_union1d\u001b[1;34m(a, b, xp)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m b\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:932\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03mFind the union of two arrays.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[249], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoting_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\classification\\functional.py:1725\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, verbose, display_format)\u001b[0m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1613\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;124;03m    This function analyzes the performance of a trained model on holdout set.\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03m    It may require re-training the model in certain cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \n\u001b[0;32m   1723\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CURRENT_EXPERIMENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\classification\\oop.py:2071\u001b[0m, in \u001b[0;36mClassificationExperiment.plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, verbose, display_format)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1959\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1969\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1970\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;124;03m    This function analyzes the performance of a trained model on holdout set.\u001b[39;00m\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;124;03m    It may require re-training the model in certain cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \n\u001b[0;32m   2069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2075\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2077\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2082\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2045\u001b[0m, in \u001b[0;36m_TabularExperiment.plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, verbose, display_format)\u001b[0m\n\u001b[0;32m   1933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1935\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1946\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1947\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;124;03m    This function takes a trained model object and returns a plot based on the\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;124;03m    test / hold-out set. The process may require the model to be re-trained in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \n\u001b[0;32m   2044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:1913\u001b[0m, in \u001b[0;36m_TabularExperiment._plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, verbose, system, display, display_format)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;66;03m# execute the plot method\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[1;32m-> 1913\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m   1915\u001b[0m     plot_filename \u001b[38;5;241m=\u001b[39m ret\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:1139\u001b[0m, in \u001b[0;36m_TabularExperiment._plot_model.<locals>.auc\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myellowbrick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROCAUC\n\u001b[0;32m   1138\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m ROCAUC(estimator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplot_kwargs)\n\u001b[1;32m-> 1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshow_yellowbrick_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pycaret\\internal\\plots\\yellowbrick.py:103\u001b[0m, in \u001b[0;36mshow_yellowbrick_plot\u001b[1;34m(visualizer, X_train, y_train, X_test, y_test, name, handle_train, handle_test, scale, save, fit_kwargs, display_format, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m handle_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    102\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScoring test/hold-out set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m     \u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m plot_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\yellowbrick\\classifier\\rocauc.py:264\u001b[0m, in \u001b[0;36mROCAUC.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mGenerates the predicted target values using the Scikit-Learn\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mestimator.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Global accuracy unless micro or macro scores are requested.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Call super to check if fitted and to compute self.score_\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# NOTE: this sets score to the base score if neither macro nor micro\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mROCAUC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# Compute the predictions for the test data\u001b[39;00m\n\u001b[0;32m    267\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_y_scores(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\yellowbrick\\classifier\\base.py:238\u001b[0m, in \u001b[0;36mClassificationScoreVisualizer.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not determine class_counts_ from previously fitted classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m         YellowbrickWarning,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# This method implements ScoreVisualizer (do not call super).\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:119\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m _union1d(y_true, y_pred, xp)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxp\u001b[38;5;241m.\u001b[39munique(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions provided by the classifier coincides with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    127\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=[0 1] and y_pred=['no' 'yes']. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x550 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(voting_clf, plot='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fbbc2797-8dde-4a4d-a7eb-150f2910fdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# VotingClassifier의 예측 확률 얻기\n",
    "y_proba = voting_clf.predict_proba(X_test_transformed)[:, 1]\n",
    "y_pred = voting_clf.predict(X_test_transformed)\n",
    "\n",
    "# y_true와 y_pred를 문자열로 변환\n",
    "y_true_str = y_test.astype(str)\n",
    "y_pred_str = y_pred.astype(str)\n",
    "\n",
    "# ROC Curve 계산\n",
    "fpr, tpr, _ = roc_curve(y_true_str, y_proba, pos_label='yes')\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# ROC Curve 시각화\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00918f-2ed2-484e-bfdf-0b4c5c275e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
